---
title: "Project Writeup"
author: "Tejus"
date: "23/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret); library(ggplot2); library(rattle); library(pheatmap); library(reshape2)

```

### Goal : 
__To build a model for predicting the manner in which an individual did an exercise (the "class" variable)__

#### Introduction :
Six young healthy participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions (class A to class E). A key requirement for effective training to have a positive impact on cardio-respiratory fitness is a proper technique. Incorrect technique has been identified as the main cause of training injuries. The researchers in this work have tried to investigate the feasibility of automatically assessing the quality of execution of weight lifting exercises and the impact of providing real-time feedback to the athlete - so-called __qualitative activity recognition__.

The class variables have been methodically formulated to define the _quality_ of the exercise done. They are defined as follows : 
      * Exactly according to the specification (Class A)
      * Throwing the elbows to the front (Class B)
      * Lifting the dumbbell only halfway (Class C)
      * Lowering the dumbbell only halfway (Class D)
      * Throwing the hips to the front (Class E)

----

#### Data loading and standardizing

* All the values are standardized by centering around mean & dividing by standard deviation.  

````{r LoadData, warning = FALSE, cache=TRUE}

trainData <- as.data.frame(read.csv2("./Data/pml-training.csv", header = T, sep =",", quote = '"'))
trainData <- trainData[,-(1:7)]; Class <- trainData[,153]

Cols <- colnames(trainData)[-153]
for(i in Cols){
   trainData[,i] <- as.numeric(as.character(trainData[,i]))
}

Blank_Cols <- apply(trainData[,-153], 2, function(Col)
      {S = sum(is.na(Col))#;print(S)
      if(S <= (length(Col)/1.5)) # Returns TRUE if the variable has <66% NAs else returns FALSE
                  {return(TRUE)}else{return(FALSE)}})

# Subsetting data with non missing/blank variables
trainData <- trainData[,c(Blank_Cols)]
#dim(trainData)

# Outliers
Indices <- apply(trainData[,-53], 2, function(Col){
                  IQR_var <- IQR(Col)
                  quantiles <- quantile(Col, probs = c(0.25,0.75), na.rm = T)
                  down <- quantiles[1] - (1.5*IQR_var)
                  up <- quantiles[2] + (1.5*IQR_var)
                  which(Col > up | Col < down)
})

# Replacing outliers with NA
for (i in 1:length(Indices)) {
   Index <- c(Indices[[i]])
   trainData[Index,i] <- NA
}

# Impute any remaining missing values and standardize
preProcObj <- preProcess(trainData, method = c("knnImpute","BoxCox"))
trainData <- data.frame(predict(preProcObj, trainData), "class" = as.factor(Class))

featurePlot(x=trainData[,1:6],
            y = trainData$class,
            plot="box", 
            layout = c(2, 2), 
            scales = list(y = list(relation="free"),
                          x = list(rot=90)),
            ## Add a key at the top 
            auto.key = list(columns = 3))

````


* Also checked if any variable had values missing and removed `r sum((Blank_Cols == FALSE))` variables which had more than `r round((100/1.5),2)`% NAs

* Also imputed the rest of small number of missing values with _knnImpute()_ method in `caret`

---- 
#### Exploratory Analysis : 

* Removing variables with low contribution to output variation.

```{r remZeroVar, cache=TRUE}
nZero_Predictors <- nearZeroVar(trainData, saveMetrics = T)
sum(nZero_Predictors$nzv == TRUE)
```

* Number of variables with near zero variance contribution is zero. Hence we retain them all. 

* Correlation analysis 

```{r VariableCor, cache=TRUE, fig.align='center', fig.width=7, fig.height=7, echo=FALSE}
Cor_Mat <- cor(trainData[,-53])
diag(Cor_Mat) <- 0 # Removing diag values

Cor_df <- data.frame(which(abs(Cor_Mat) > 0.8, arr.ind = T))
# Some highly correlated variable heatmap
pheatmap(Cor_Mat[c(unique(Cor_df$row)),c(unique(Cor_df$col))])
```

* Basic correlation analysis for finding variables that are highly correlated tells us that almost `r length(sort(unique(Cor_df$col)))` variables are highly correlated `(abs(cor_value) > 0.8)` with each other.

* We cannot simply remove the variable because that would result in creating a bias. So we choose to use PCA and use those variables for model building.

* We could also have opted for other methods like `Boosting` but since we're not concerned much about interpretability of individual variables we will go ahead with our lazy option of PCA.

```{r PCA_Preprocess, cache=TRUE, echo=FALSE, fig.align='center', fig.width=8}

prCom <- preProcess(trainData, method = "pca")
trainData.PCA <- predict(prCom, newdata = trainData)

trainData.melted <- melt(trainData, id = "class", measure.vars = c(colnames(trainData[,-53])))
# 
'gg <- ggplot(aes(x = class, y =value, group = class), data = trainData.melted) +
   + facet_wrap(~variable)
'
gg <- ggplot(aes(x = class,y =value, group = class), data = trainData.melted) + geom_boxplot(aes(fill=class)) + facet_wrap(~variable)
plot(gg)

```


----

#### Testing the model

* First we do the exact same transformations to the test data that we did to the training data.

```{r TestData, cache=TRUE, eval=FALSE, echo=FALSE}
testData <- as.data.frame(read.csv2("./Data/pml-testing.csv", header = T, sep =",", quote = '"'))
testData <- testData[,-(1:7)]; Test.Class <- testData[,153]

# Subsetting data with non missing/blank variables
testData <- testData[,c(Blank_Cols)]

# Impute
testData <- data.frame(predict(preProcObj, testData), "class" = as.factor(Test.Class))
testData.PCA <- predict(prCom, newdata = testData)

```









